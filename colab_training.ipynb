{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ab617ea2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab617ea2",
        "outputId": "82bdc0e2-09f8-4d21-aa31-b4a4b7bb6e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install -q torch datasets transformers numpy matplotlib\n",
        "print(\"Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c05541c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05541c4",
        "outputId": "6a220420-3ed8-4404-af5f-2c4dcead86ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-FINAL'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 145 (delta 80), reused 101 (delta 38), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (145/145), 1.03 MiB | 25.13 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "/content/NLP-FINAL/src\n",
            "Repository cloned\n"
          ]
        }
      ],
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/ahuliangbo/NLP-FINAL.git\n",
        "%cd NLP-FINAL/src\n",
        "print(\"Repository cloned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "yBIgFWf-Hgnm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBIgFWf-Hgnm",
        "outputId": "71de6717-9f49-4c3c-c649-6e16906836c7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 64D-2L-adam\n",
            "Epoch 1: loss=7.0930, acc=0.3069\n",
            "Epoch 2: loss=4.2043, acc=0.4971\n",
            "Epoch 3: loss=3.0990, acc=0.6143\n",
            "Epoch 4: loss=2.3565, acc=0.7098\n",
            "Epoch 5: loss=1.8240, acc=0.7796\n",
            "Training 128D-4L-adam\n",
            "Epoch 1: loss=5.2010, acc=0.4670\n",
            "Epoch 2: loss=2.6787, acc=0.6992\n",
            "Epoch 3: loss=1.7082, acc=0.8200\n",
            "Epoch 4: loss=1.1416, acc=0.8858\n",
            "Epoch 5: loss=0.7896, acc=0.9251\n",
            "Training 256D-6L-adam\n",
            "Epoch 1: loss=3.7152, acc=0.6320\n",
            "Epoch 2: loss=1.4805, acc=0.8684\n",
            "Epoch 3: loss=0.7823, acc=0.9398\n",
            "Epoch 4: loss=0.4447, acc=0.9731\n",
            "Epoch 5: loss=0.2576, acc=0.9876\n",
            "Training 128D-4L-adam\n",
            "Epoch 1: loss=5.2352, acc=0.4659\n",
            "Epoch 2: loss=2.6912, acc=0.6955\n",
            "Epoch 3: loss=1.7192, acc=0.8176\n",
            "Epoch 4: loss=1.1497, acc=0.8843\n",
            "Epoch 5: loss=0.7957, acc=0.9240\n",
            "Training 128D-4L-adamw\n",
            "Epoch 1: loss=5.2154, acc=0.4658\n",
            "Epoch 2: loss=2.6838, acc=0.6984\n",
            "Epoch 3: loss=1.7101, acc=0.8198\n",
            "Epoch 4: loss=1.1466, acc=0.8855\n",
            "Epoch 5: loss=0.7932, acc=0.9251\n",
            "Training 128D-4L-sgd\n",
            "Epoch 1: loss=9.6197, acc=0.0893\n",
            "Epoch 2: loss=8.5545, acc=0.1610\n",
            "Epoch 3: loss=7.7497, acc=0.2263\n",
            "Epoch 4: loss=7.2351, acc=0.2803\n",
            "Epoch 5: loss=6.9226, acc=0.2973\n",
            "Figure(1400x400)\n",
            "Figure(1400x400)\n",
            " Model Total Time (s) Avg Epoch (s) Final Loss Best Loss Final Acc Peak Mem (GB)\n",
            " small           22.2           4.4     1.8240    1.8240    0.7796          0.15\n",
            "medium           29.1           5.8     0.7896    0.7896    0.9251          0.21\n",
            " large           50.7          10.1     0.2576    0.2576    0.9876          0.34\n",
            "Optimizer Total Time (s) Avg Epoch (s) Final Loss Best Loss Final Acc\n",
            "     ADAM           29.4           5.9     0.7957    0.7957    0.9240\n",
            "    ADAMW           29.9           6.0     0.7932    0.7932    0.9251\n",
            "      SGD           28.3           5.7     6.9226    6.9226    0.2973\n",
            "Best model final loss: large\n",
            "Fastest model: small\n",
            "Best optimizer: adamw\n",
            "Fastest optimizer: sgd\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "!python run_experiemnts.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python positional_ablation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujFhyN5_vw5J",
        "outputId": "14214efd-7420-4644-dd26-8933018fac44"
      },
      "id": "ujFhyN5_vw5J",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--Training pos_type=sinusoidal--\n",
            "pos=sinusoidal epoch=1 loss=7.2872\n",
            "pos=sinusoidal epoch=2 loss=4.7631\n",
            "pos=sinusoidal epoch=3 loss=3.7126\n",
            "pos=sinusoidal epoch=4 loss=3.0295\n",
            "pos=sinusoidal epoch=5 loss=2.5037\n",
            "\n",
            "--Training pos_type=learned--\n",
            "pos=learned epoch=1 loss=7.5371\n",
            "pos=learned epoch=2 loss=5.1276\n",
            "pos=learned epoch=3 loss=4.1580\n",
            "pos=learned epoch=4 loss=3.5001\n",
            "pos=learned epoch=5 loss=2.9664\n",
            "\n",
            "--Training pos_type=rotary--\n",
            "pos=rotary epoch=1 loss=7.2273\n",
            "pos=rotary epoch=2 loss=4.5934\n",
            "pos=rotary epoch=3 loss=3.5055\n",
            "pos=rotary epoch=4 loss=2.8195\n",
            "pos=rotary epoch=5 loss=2.3019\n",
            "pos=sinusoidal len=64 ppl=8.87\n",
            "pos=sinusoidal len=128 ppl=9.29\n",
            "pos=sinusoidal len=192 ppl=9.71\n",
            "pos=sinusoidal len=256 ppl=9.96\n",
            "pos=learned len=64 ppl=13.54\n",
            "pos=learned len=128 ppl=14.51\n",
            "pos=learned len=192 ppl=14.95\n",
            "pos=learned len=256 ppl=15.21\n",
            "pos=rotary len=64 ppl=7.83\n",
            "pos=rotary len=128 ppl=8.12\n",
            "pos=rotary len=192 ppl=8.30\n",
            "pos=rotary len=256 ppl=8.41\n",
            "Saved loss plot to /content/NLP-FINAL/src/outputs/pos_ablation_loss.png\n",
            "Saved perplexity plot to /content/NLP-FINAL/src/outputs/pos_ablation_perplexity.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pretrained_comparison.py"
      ],
      "metadata": {
        "id": "K-ogCFfBv0lj"
      },
      "id": "K-ogCFfBv0lj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}